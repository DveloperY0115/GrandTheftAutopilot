{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pilotNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DveloperY0115/GrandTheftAutopilot/blob/pilotNet/pilotNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL6vLyIElvwD"
      },
      "source": [
        "# PilotNet training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk_e_HzMc2df"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hJwANvl35F"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import sklearn\r\n",
        "import glob\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bDDeCtemVuk"
      },
      "source": [
        "## Mount Google Drive into Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bVXH_5rmEVs",
        "outputId": "98177c8e-d87a-4d18-a4d2-54a5f9f9cbaf"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB2G5mbCfFsC"
      },
      "source": [
        "## [In Progress] Copy datasets from Google Drive to Colab\n",
        "\n",
        "Since the overhead caused by network transaction is NOT negligible, one have to\n",
        "copy all the data required at the beginning of the experiment for best performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8smPtbKvfEa8",
        "outputId": "943ab3e0-aec0-4634-f65b-7c4a941fa92f"
      },
      "source": [
        "import sys\n",
        "# set base path to the top of our project directory\n",
        "base = Path('/content/drive/MyDrive/AutopilotDrive')\n",
        "sys.path.append(str(base))\n",
        "\n",
        "dataset_path = base/'dataset.zip'\n",
        "\n",
        "# copy zipped dataset from Google Drive\n",
        "!cp \"{dataset_path}\"\n",
        "\n",
        "# unzip the files\n",
        "!unzip -q dataset.zip\n",
        "\n",
        "# remove zipped file to save storage\n",
        "!rm dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: missing destination file operand after '/content/drive/MyDrive/AutopilotDrive/dataset.zip'\n",
            "Try 'cp --help' for more information.\n",
            "unzip:  cannot find or open dataset.zip, dataset.zip.zip or dataset.zip.ZIP.\n",
            "rm: cannot remove 'dataset.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4Pnosn9hxVS"
      },
      "source": [
        "## Load Dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7OAB5aRAumV"
      },
      "source": [
        "import pathlib\r\n",
        "\r\n",
        "# set directory to datasets\r\n",
        "data_dir = \"/content/drive/MyDrive/AutopilotDrive/dataset/\"\r\n",
        "data_dir = pathlib.Path(data_dir)\r\n",
        "\r\n",
        "# check # of images\r\n",
        "# img_count = len(list(data_dir.glob('*/imgs/*.jpg')))\r\n",
        "print(img_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBEVjkEjlnuZ"
      },
      "source": [
        "## Define Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APw29y97AZgF"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "# Keras implemented with TF backend\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, BatchNormalization\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\r\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juim2r12TWaW"
      },
      "source": [
        "# define custom scikit-learn estimator & transformer performing MinMaxScaling on each channels\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "class ImageMinMaxScaler(BaseEstimator, TransformerMixin):\n",
        "\n",
        "  def __init__(self):\n",
        "    return\n",
        "\n",
        "  def fit(self, X=None, y=None):\n",
        "    return self\n",
        "    \n",
        "  def transform(self, X, y=None):\n",
        "    # scale every pixel value to fit in [0, 1]\n",
        "    result = X / 255\n",
        "\n",
        "    return result\n",
        "\n",
        "  def fit_transform(self, X, y=None):\n",
        "    self.fit()\n",
        "\n",
        "    result = self.transform(X)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0QIKZAvnM13"
      },
      "source": [
        "\n",
        "# define custom scikit-learn estimator & transformer resizing given image\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class ImageResizer(TransformerMixin):\n",
        "\n",
        "  def __init__(self, target_size=(200, 66)):\n",
        "      self.target_size = target_size\n",
        "      return\n",
        "\n",
        "  def fit(self, X=None, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, X):\n",
        "      result = cv2.resize(X, self.target_size, interpolation=cv2.INTER_AREA)\n",
        "      return np.swapaxes(result, axis1=0, axis2=1)\n",
        "\n",
        "  def fit_transform(self, X, y=None):\n",
        "      return self.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61D4s1vsRAm9"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([                     \n",
        "                     ('ImageMinMaxScaler', ImageMinMaxScaler()), # scales the pixel values to range [0, 1]\n",
        "                     ('ImageResizer', ImageResizer())  # resizes given image to match the input layer size of the NN\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALqJ3oLis-3R"
      },
      "source": [
        "## Define Custom dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQcQaVsDtB1I"
      },
      "source": [
        "import pathlib\n",
        "import math\n",
        "\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class Dataloader(Sequence):\n",
        "  def __init__(self, dataset_dir, batch_size=32, shuffle=False):\n",
        "    self.dataset_dir = pathlib.Path(dataset_dir)\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle= shuffle\n",
        "    self.num_img = len(list(self.dataset_dir.glob('imgs/*.jpg')))\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return math.ceil(self.num_img / self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POkakZB-DoQF"
      },
      "source": [
        "def img_to_arr(p):\r\n",
        "    with image.load_img(p) as img:\r\n",
        "        img = image.img_to_array(img)\r\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzB_Xsq3d6Ji"
      },
      "source": [
        "target_dataset = \"/content/drive/MyDrive/AutopilotDrive/dataset/\"\n",
        "df = pd.read_csv(target_dataset + \"/datasets_mod.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqgNmcpgeMHi"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array # Image Related\n",
        "\n",
        "random_indices = np.random.randint(low=0, high=len(df), size=100)\n",
        "\n",
        "X_train = np.array([img_to_arr(target_dataset + \"../\" + image_name) for image_name in df['drive_view'].iloc[random_indices]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVfQrl7FIQJs"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "for i in range(len(random_indices)):\r\n",
        "    scaler_R = StandardScaler().fit(X_train[i][:,:,0])\r\n",
        "    scaler_G = StandardScaler().fit(X_train[i][:,:,1])\r\n",
        "    scaler_B = StandardScaler().fit(X_train[i][:,:,2])\r\n",
        "\r\n",
        "def normalize(img):\r\n",
        "    img[:,:,0] = scaler_R.transform(img[:,:,0])\r\n",
        "    img[:,:,1] = scaler_G.transform(img[:,:,1])\r\n",
        "    img[:,:,2] = scaler_B.transform(img[:,:,2])\r\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_h4pmPf_qd_"
      },
      "source": [
        "# define generator that loops through the data\r\n",
        "def generator(df, batch_size, img_shape, should_shuffle):\r\n",
        "    # shuffle dataframe for each epoch\r\n",
        "    if should_shuffle:\r\n",
        "        df = shuffle(df)\r\n",
        "        \r\n",
        "    img_list = df['drive_view']\r\n",
        "    steer = df['control']\r\n",
        "    \r\n",
        "    # create empty batch\r\n",
        "    batch_img = np.zeros((batch_size,) + img_shape)\r\n",
        "    batch_label = np.zeros((batch_size, 1))\r\n",
        "    \r\n",
        "    index = 0\r\n",
        "    while True:\r\n",
        "        for i in range(batch_size):\r\n",
        "            img_name = img_list[index]\r\n",
        "            arr = img_to_arr(target_dataset + \"../\" + img_name)\r\n",
        "            \r\n",
        "            batch_img[i] = normalize(arr, scaler_R, scaler_G, scaler_B)\r\n",
        "            batch_label[i] = steer[index]\r\n",
        "            \r\n",
        "            index += 1\r\n",
        "            if index == len(img_list):\r\n",
        "                index = 0\r\n",
        "            \r\n",
        "        yield batch_img, batch_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGN7iNorsw3p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "784a97da-d8ac-4dfc-9d14-c6c10754ebd5"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>drive_view</th>\n",
              "      <th>control</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  control\n",
              "0           0  ...        3\n",
              "1           1  ...        3\n",
              "2           2  ...        1\n",
              "3           3  ...        1\n",
              "4           4  ...        1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab6f1B2yAtD9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "df_train, df_valid = train_test_split(df, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgaDuBDgEQy3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9b29c9b6-2931-43b9-be08-154df9aba1de"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>drive_view</th>\n",
              "      <th>control</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17391</th>\n",
              "      <td>19245</td>\n",
              "      <td>8465</td>\n",
              "      <td>19246</td>\n",
              "      <td>./dataset/210119_12-16-36_data/imgs/drive_view...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17524</th>\n",
              "      <td>19378</td>\n",
              "      <td>8598</td>\n",
              "      <td>19379</td>\n",
              "      <td>./dataset/210119_12-16-36_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64483</th>\n",
              "      <td>72823</td>\n",
              "      <td>2562</td>\n",
              "      <td>72824</td>\n",
              "      <td>./dataset/210126_07-25-00_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1974</th>\n",
              "      <td>2157</td>\n",
              "      <td>2157</td>\n",
              "      <td>2158</td>\n",
              "      <td>./dataset/210119_12-14-48_data/imgs/drive_view...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26831</th>\n",
              "      <td>28685</td>\n",
              "      <td>562</td>\n",
              "      <td>28686</td>\n",
              "      <td>./dataset/210119_12-24-51_data/imgs/drive_view...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...  control\n",
              "17391       19245  ...        0\n",
              "17524       19378  ...        1\n",
              "64483       72823  ...        1\n",
              "1974         2157  ...        1\n",
              "26831       28685  ...        0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb3rXnWHEWvs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e10983ff-0584-4ae7-9642-5ebff5bc29a2"
      },
      "source": [
        "df_train['drive_view'].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./dataset/210119_12-16-36_data/imgs/drive_view8465.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Zqjk3aAak1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1102f003-5b5e-48c4-c0d8-cf5579257f7f"
      },
      "source": [
        "sample_image = img_to_arr(target_dataset + \"../\" + df_train['drive_view'].iloc[0])\r\n",
        "input_shape = sample_image.shape\r\n",
        "batch_size = 32\r\n",
        "train_steps = (df_train.shape[0] / batch_size) + 1\r\n",
        "val_steps = (df_valid.shape[0] / batch_size) + 1\r\n",
        "\r\n",
        "print(\"input_shape: %s, batch_size: %d, train_steps: %d, val_steps: %d\" % \r\n",
        "      (input_shape, batch_size, train_steps, val_steps))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (256, 455, 3), batch_size: 32, train_steps: 1775, val_steps: 444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3tjsRo-BadG"
      },
      "source": [
        "train_batch = generator(df_train, batch_size, input_shape, True)\r\n",
        "val_batch = generator(df_valid, batch_size, input_shape, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkhDzeinlicQ"
      },
      "source": [
        "# Define Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16xeasSVL1mK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab263b2-fb87-4da7-b158-e9a1f81e7b1c"
      },
      "source": [
        "drop_out_rate = 0.2\n",
        "\n",
        "model = models.Sequential()\n",
        "# model.add(Rescaling(scale=1./255))\n",
        "\n",
        "# three Conv2D layers with 5 x 5 kernels, and 2 x 2 strides\n",
        "model.add(Conv2D(filters=24, kernel_size=(5, 5), strides=(2, 2),\n",
        "                              padding='valid', activation='relu', input_shape=(200, 66, 3)))\n",
        "model.add(Conv2D(filters=36, kernel_size=(5, 5), strides=(2, 2),\n",
        "                              padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=48, kernel_size=(5, 5), strides=(2, 2),\n",
        "                              padding='valid', activation='relu'))\n",
        "\n",
        "# two Conv2D layers with 3 x 3 kernels, and no strides\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                              padding='valid', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "                              padding='valid', activation='relu'))\n",
        "\n",
        "# and data flows to three fully-connected layers\n",
        "model.add(Flatten())   # (None, 1152)\n",
        "model.add(Dense(units=1152))\n",
        "model.add(Dropout(rate=drop_out_rate))\n",
        "model.add(Dense(units=100))\n",
        "model.add(Dropout(rate=drop_out_rate))\n",
        "model.add(Dense(units=50))\n",
        "model.add(Dropout(rate=drop_out_rate))\n",
        "model.add(Dense(units=10))\n",
        "model.add(Dropout(rate=drop_out_rate))\n",
        "model.add(Dense(units=5, activation='softmax'))\n",
        "\n",
        "# build the pilotNet model\n",
        "model.build(input_shape=(None, 200, 66, 3))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 98, 31, 24)        1824      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 47, 14, 36)        21636     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 5, 48)         43248     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 3, 64)         27712     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 18, 1, 64)         36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1152)              1328256   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               115300    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                510       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 55        \n",
            "=================================================================\n",
            "Total params: 1,580,519\n",
            "Trainable params: 1,580,519\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Po1fP6_L6a2"
      },
      "source": [
        "model.compile(optimizer='adam',\r\n",
        "                loss='cross_entropy',\r\n",
        "                metrics=['f1_score'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5TLazMtC8Bl"
      },
      "source": [
        "model_path = target_dataset + \"/model\"\r\n",
        "# define callbacks\r\n",
        "cur_model = 'PilotNet_v1'\r\n",
        "csv_logger = CSVLogger(os.path.join(\"./\", cur_model + '.log'))\r\n",
        "\r\n",
        "model_file_name= os.path.join(model_path, cur_model + '-{epoch:03d}-{val_loss:.5f}.h5')\r\n",
        "checkpoint = ModelCheckpoint(model_file_name, verbose=0, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_BfVlnFDEWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8528f00-b1d2-40a2-9014-905c9a2a8681"
      },
      "source": [
        "print(type(train_batch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'generator'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiEsMSXhDJJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "6e442103-2299-471b-a1f2-b68b8d92ccb7"
      },
      "source": [
        "model.fit_generator(train_batch, train_steps, epochs=20, verbose=1, \r\n",
        "                    callbacks=[csv_logger, checkpoint], \r\n",
        "                    validation_data=val_batch, \r\n",
        "                    validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-4cf42d7624dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     validation_steps=val_steps)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    834\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ti4AFXGtFZx"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJuQqek8tGgr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}